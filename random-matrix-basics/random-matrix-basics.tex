\documentclass{article}

\input{../preamble.sty}
\usepackage{lmodern}
\usepackage{xcolor}
\usepackage{diagbox}
\usepackage{xr-hyper}
\graphicspath{ {../../code/fig/} }

\newcommand{\bx}{\boldsymbol{x}}
\newcommand{\bv}{\boldsymbol{v}}
\newcommand{\bX}{\boldsymbol{X}}
\newcommand{\bSigma}{\boldsymbol{\Sigma}}
\newcommand{\bS}{\boldsymbol{S}}
\newcommand{\bI}{\boldsymbol{I}}

\title{ {\bf The Basics of Random Matrix Theory} }

\begin{document}
	
\maketitle
\RaggedRight

\abstract{This document records some elementary background on random matrix theory for sample covariance matrices.}

\section{Introduction}

Suppose random vectors $\bx_1,\ldots,\bx_n \in \Reals^p$ are independently sampled from a Normal distribution with mean $0$ and covariance $\bSigma$. The sample covariance matrix is
$$
\bS = \frac{1}{n}\sum_{i = 1}^{n} \bx_i \bx_i^{\top} = \frac{1}{n}\bX \bX^{\top},
$$ 
where $\bX \in \Reals^{n \times p}$ is matrix with rows $\bX_{i\cdot} = \bx_i$. Random matrix theory describes the asymptotic behavior of the sample eigenvalues $\lambda_i(\bS) = \lambda_i(\bS)$ and eigenvectors $\bv_i = \bv_i(\bS)$ of $\bS$, in the \emph{proportional asymptotics} limit $n,p \to \infty, p/n \to \gamma \in (0,\infty)$. 

\subsection{Stieltjes transform}
The Stieltjes transform is a key analytical device used to prove asymptotic convergence of spectral distributions of random matrices. The {\bf Stieltjes transform} of a measure $\mu$ is defined for $z \in \mathbb{C}\setminus\supp(\mu)$ as
$$
m_{\mu}(z) := \int \frac{1}{t - z} \,d\mu(t).
$$
The measure $\mu$ can be recovered from its Stieltjes transform via the {\bf Stieltjes inversion formula}. At a given $\tau \in \supp(\mu)$, if $\lim_{\varepsilon \to 0} \Im m_{\mu}(\tau + \varepsilon i)$ exists then $m_{\mu}$ is continuous at $t$, with density $f_{\mu}(\tau) = \frac{1}{\pi}\lim_{\varepsilon} \Im m_{\mu}(\tau + \varepsilon i)$. To see this:
\begin{align*}
	\lim_{\varepsilon \to 0}\Im m_{\mu}(\tau + \varepsilon i) 
	& = 
	\lim_{\varepsilon \to 0}\int \Im(\frac{1}{t - (\tau + \varepsilon i)} \,d\mu(t) \\
	& = \lim_{\varepsilon \to 0} \int \frac{\varepsilon}{(t - \tau)^2 + \varepsilon^2} \,d\mu(t) \\
	& = \frac{1}{\pi}f(\tau).
\end{align*} 

\section{Marchenko-Pastur distribution}
Let $\hat{H}_n(\tau)$ represent the empirical spectral distribution of the eigenvalues of $\bSigma$:
$$
\hat{H}_n(t) := \frac{1}{p} \sum_{i = 1}^{p} \1\{\lambda_i(\bSigma) \leq t\}.
$$
Suppose that $\hat{H}_n(t)$ converges weakly to a limiting spectral distribution $H(t)$ as $p \to \infty$. Then the spectral distribution $\hat{F}_n(t)$ of the sample covariance $\bS$ also converges to continuum limit $F_{\gamma,H}(t)$, which we will call a {\bf generalized Marchenko-Pastur distribution}. Random matrix theory provides the analytical tools necessary to prove this result and describe the resulting continuum limit.

The most basic case is $\bSigma = \bI, \gamma < 1$, $\hat{H}_n(\tau) = H_1(\tau) = \1\{\tau \leq 1\}$. In this case $\hat{F}_n(t)$ converges weakly to the {\bf Marchenko-Pastur distribution} $F_{\gamma}(t)$. The Marchenko-Pastur distribution has a density $f_{\gamma}(t)$ supported on $[t^{-},t^{+}] := [1 - \sqrt{\gamma}, 1 + \sqrt{\gamma}]$, with 
$$
f_{\gamma}(t) := \frac{\sqrt{(t^{+} - t)(t - t^{-})}}{2 \pi \gamma t}, \quad \textrm{for $t \in [t^{-},t^{+}]$.}
$$
If additionally $\gamma > 1$, then $F_{\gamma}$ has an atom at $0$ of magnitude $1 - 1/\gamma$. 

\subsection{Silverstein's equation}
Let $m_{\gamma}$ be the Stieltjes transform of the limiting generalized Marchenko-Pastur distribution $F_{\gamma,H}$. It can be shown that $m_{\gamma}$ satisfies the fixed point equation
$$
z = -\frac{1}{m(z)} + \gamma \int \frac{t}{1 + tm(z)} \,dH(t), \quad \textrm{for all $z \in \C_{+}$.}
$$
In the specific case of $\bSigma = \bI$ and $H = H_1$, this is simply
$$
z = -\frac{1}{m(z)} + \gamma \frac{1}{1 + m(z)}.
$$
Rearranging and solving the resulting quadratic equation for $m$ gives
$$
m(z) = 
$$

\subsection{Stieltjes inversion formula}

	
	
\end{document}