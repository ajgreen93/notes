\documentclass{article}

\input{../preamble.sty}
\usepackage{lmodern}
\usepackage{xcolor}
\usepackage{diagbox}
\usepackage{xr-hyper}
\graphicspath{ {../../code/fig/} }

\newcommand{\bx}{\boldsymbol{x}}
\newcommand{\bv}{\boldsymbol{v}}
\newcommand{\bX}{\boldsymbol{X}}
\newcommand{\bSigma}{\boldsymbol{\Sigma}}
\newcommand{\bS}{\boldsymbol{S}}
\newcommand{\bI}{\boldsymbol{I}}

\title{ {\bf The Basics of Random Matrix Theory} }

\begin{document}
	
\maketitle
\RaggedRight

\abstract{This document records some elementary background on random matrix theory for sample covariance matrices.}

\section{Introduction}

Suppose random vectors $\bx_1,\ldots,\bx_n \in \Reals^p$ are independently sampled from a Normal distribution with mean $0$ and covariance $\bSigma$. The sample covariance matrix is
$$
\bS = \frac{1}{n}\sum_{i = 1}^{n} \bx_i \bx_i^{\top} = \frac{1}{n}\bX \bX^{\top},
$$ 
where $\bX \in \Reals^{n \times p}$ is matrix with rows $\bX_{i\cdot} = \bx_i$. Random matrix theory describes the asymptotic behavior of the sample eigenvalues $\lambda_i(\bS) = \lambda_i(\bS)$ and eigenvectors $\bv_i = \bv_i(\bS)$ of $\bS$, in the \emph{proportional asymptotics} limit $n,p \to \infty, p/n \to \gamma \in (0,\infty)$. 

\subsection{Stieltjes transform}
The Stieltjes transform is a key analytical device used to prove asymptotic convergence of spectral distributions of random matrices. The {\bf Stieltjes transform} of a measure $\mu$ is defined for $z \in \mathbb{C}\setminus\supp(\mu)$ as
$$
m_{\mu}(z) := \int \frac{1}{t - z} \,d\mu(t), \quad m_{\mu}(z) \in C_{+}.
$$
The measure $\mu$ can be recovered from its Stieltjes transform via the {\bf Stieltjes inversion formula}. At a given $\tau \in \supp(\mu)$, if $\lim_{\varepsilon \to 0} \Im m_{\mu}(\tau + \varepsilon i)$ exists then $m_{\mu}$ is continuous at $t$, with density $f_{\mu}(\tau) = \frac{1}{\pi}\lim_{\varepsilon} \Im m_{\mu}(\tau + \varepsilon i)$. To see this:
\begin{align*}
	\lim_{\varepsilon \to 0}\Im m_{\mu}(\tau + \varepsilon i) 
	& = 
	\lim_{\varepsilon \to 0}\int \Im(\frac{1}{t - (\tau + \varepsilon i)} \,d\mu(t) \\
	& = \lim_{\varepsilon \to 0} \int \frac{\varepsilon}{(t - \tau)^2 + \varepsilon^2} \,d\mu(t) \\
	& = \frac{1}{\pi}f(\tau).
\end{align*} 

\section{Marchenko-Pastur distribution}
Let $\hat{H}_n(\tau)$ represent the empirical spectral distribution of the eigenvalues of $\bSigma$:
$$
\hat{H}_n(t) := \frac{1}{p} \sum_{i = 1}^{p} \1\{\lambda_i(\bSigma) \leq t\}.
$$
Suppose that $\hat{H}_n(t)$ converges weakly to a limiting spectral distribution $H(t)$ as $p \to \infty$. Then the spectral distribution $\hat{F}_n(t)$ of the sample covariance $\bS$ also converges to continuum limit $F_{\gamma,H}(t)$, which we will call a {\bf generalized Marchenko-Pastur distribution}. Random matrix theory provides the analytical tools necessary to prove this result and describe the resulting continuum limit.

\subsection{Silverstein's equation}
Let $m_{\gamma,H}$ be the Stieltjes transform of the limiting generalized Marchenko-Pastur distribution $F_{\gamma,H}$. The companion transform is $v_{\gamma,H} := \gamma m_{\gamma,H}(z) - \frac{(1 - \gamma)}{z}$. It can be shown, via the leave-one-out approach, that the companion transform satisfies the self-consistency equation
\begin{equation}
	\label{eqn:silverstein}
	z = -\frac{1}{v(z)} + \gamma \int \frac{t}{1 + tv(z)} \,dH(t), \quad \textrm{for all $z \in \C_{+}$.}
\end{equation}



\subsection{Stieltjes inversion formula}

\section{Examples}

\subsection{Identity covariance}

The most basic case is $\bSigma = \bI, \gamma < 1$, $\hat{H}_n(\tau) = H_1(\tau) = \1\{\tau \leq 1\}$. In this case $\hat{F}_n(t)$ converges weakly to the {\bf Marchenko-Pastur distribution} $F_{\gamma}(t)$. The Marchenko-Pastur distribution has a density $f_{\gamma}(t)$ supported on $[t^{-},t^{+}] := [1 - \sqrt{\gamma}, 1 + \sqrt{\gamma}]$, with 
$$
f_{\gamma}(t) := \frac{\sqrt{(t^{+} - t)(t - t^{-})}}{2 \pi \gamma t}, \quad \textrm{for $t \in [t^{-},t^{+}]$.}
$$
If additionally $\gamma > 1$, then $F_{\gamma}$ has an atom at $0$ of magnitude $1 - 1/\gamma$. 

To show this, notice that when $H = \delta_1$ the self-consistency equation~\eqref{eqn:silverstein} reduces to
$$
z = -\frac{1}{v(z)} + \frac{\gamma}{1 + v(z)}.
$$
Using the definition of $m$, this can be rearranged to 
$$
m(z)= \frac{1}{(1 - \gamma) - \gamma m z - z}.
$$
Taking the resulting quadratic equation and solving for $m$ yields two solutions, 
$$
\frac{(1 - \gamma - z) \pm \sqrt{(1 + \gamma - z)^2 - 4 \gamma}}{2 \gamma z}.
$$
If we adopt the usual convention that $\sqrt{z} \in \mathbb{C}_{+}$ refers to the positive branch of a complex number, then recalling that $m(z) \in \mathbb{C}_{+}$, it follows that 
\begin{align*}
m_{\gamma}(z) 
& = \frac{(1 - \gamma - z) + \sqrt{(1 + \gamma - z)^2 - 4 \gamma}}{2 \gamma z} \\
& = \frac{(1 - \gamma - z) + \sqrt{( (1 + \sqrt{\gamma})^2 - z)((1 - \sqrt{\gamma})^2 - z)}}{2 \gamma z}.
\end{align*}
From here we can compute the density of the Marchenko-Pastur distribution by applying the Stieltjes inversion formula:
\begin{align*}
f_{\gamma}(t) 
& = \frac{1}{\pi}\lim_{\varepsilon \to 0} \Im m_{\gamma}(t + i \varepsilon) \\
& = \frac{1}{\pi} \Im \frac{\sqrt{( (1 + \sqrt{\gamma})^2 - t)((1 - \sqrt{\gamma})^2 - t)}}{2 \gamma t} \\
& = \frac{1}{\pi} \frac{\sqrt{( (1 + \sqrt{\gamma})^2 - t)(t - (1 - \sqrt{\gamma})^2)}}{2 \gamma t}.
\end{align*}

	
	
\end{document}