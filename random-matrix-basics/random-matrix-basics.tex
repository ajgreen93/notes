\documentclass{article}

\input{../preamble.sty}
\usepackage{lmodern}
\usepackage{xcolor}
\usepackage{diagbox}
\usepackage{xr-hyper}

\newcommand{\bx}{\boldsymbol{x}}
\newcommand{\bz}{\boldsymbol{z}}
\newcommand{\bv}{\boldsymbol{v}}
\newcommand{\bw}{\boldsymbol{w}}
\newcommand{\bq}{\boldsymbol{q}}
\newcommand{\bX}{\boldsymbol{X}}
\newcommand{\bbeta}{\boldsymbol{\beta}}
\newcommand{\bSigma}{\boldsymbol{\Sigma}}
\newcommand{\bTheta}{\boldsymbol{\Theta}}
\newcommand{\bS}{\boldsymbol{S}}
\newcommand{\bB}{\boldsymbol{B}}
\newcommand{\bQ}{\boldsymbol{Q}}
\newcommand{\bP}{\boldsymbol{P}}
\newcommand{\bR}{\boldsymbol{R}}
\newcommand{\bI}{\boldsymbol{I}}
\newcommand{\bZ}{\boldsymbol{Z}}
\newcommand{\Complex}{\mathbb{C}}

\newcommand{\interior}{\mathrm{int}}
\newcommand{\range}{\mathrm{range}}

\newcommand{\convweak}{\Rightarrow}

\title{ {\bf The Basics of Random Matrix Theory} }

\begin{document}
	
\maketitle
\RaggedRight

\begin{abstract}
	This document records some elementary background on random matrix theory for sample covariance matrices.
\end{abstract}

\section{Introduction}

Suppose random vectors $\bx_1,\ldots,\bx_n \in \Reals^p$ are independently sampled from a Normal distribution with mean $0$ and covariance $\bSigma$. The sample covariance matrix is
$$
\bS = \frac{1}{n}\sum_{i = 1}^{n} \bx_i \bx_i^{\top} = \frac{1}{n}\bX \bX^{\top},
$$ 
where $\bX \in \Reals^{n \times p}$ is matrix with rows $\bX_{i\cdot} = \bx_i$. Random matrix theory describes the asymptotic behavior of the sample eigenvalues $\lambda_i(\bS) = \lambda_i(\bS)$ and eigenvectors $\bv_i = \bv_i(\bS)$ of $\bS$, in the \emph{proportional asymptotics} limit $n,p \to \infty, p/n \to \gamma \in (0,\infty)$. This is achieved by through the device of the Stieltjes transform which packages the spectral information of $\bS$, and is the key analytical tool used to prove asymptotic convergence of spectral distributions of random matrices.

\subsection{Stieltjes transform}
The {\bf Stieltjes transform} of a measure $\mu$ is defined for $z \in \mathbb{C}\setminus\supp(\mu)$ as
$$
m_{\mu}(z) := \int \frac{1}{t - z} \,d\mu(t), \quad m_{\mu}(z) \in C_{+}.
$$
It is the case that $m_{\mu}$ is continuous in $\Complex_{+}$, though it is not continuous over all of its support. We will extend $m_{\mu}(z)$ by continuity to be defined for all $z \in \mathbb{C} \setminus0$, that is, for $x \in \supp(\mu) \setminus 0$, we will define $m_{\mu}(x) := \lim_{\varepsilon \to 0} m_{\mu}(x + \varepsilon i)$. 
The measure $\mu$ can be recovered from its Stieltjes transform via the {\bf Stieltjes inversion formula}. At a given $\tau \in \supp(\mu)$, if $\lim_{\varepsilon \to 0} \Im m_{\mu}(\tau + \varepsilon i)$ exists then $m_{\mu}$ is continuous at $t$, with density $f_{\mu}(\tau) = \frac{1}{\pi}\lim_{\varepsilon} \Im m_{\mu}(\tau + \varepsilon i)$. To see this:
\begin{align*}
	\lim_{\varepsilon \to 0}\Im m_{\mu}(\tau + \varepsilon i) 
	& = 
	\lim_{\varepsilon \to 0}\int \Im\Big(\frac{1}{t - (\tau + \varepsilon i)}\Big) \,d\mu(t) \\
	& = \lim_{\varepsilon \to 0} \int \frac{\varepsilon}{(t - \tau)^2 + \varepsilon^2} \,d\mu(t) \\
	& = \pi f(\tau),
\end{align*} 
with the last equality following since the Poisson kernels $P_{\varepsilon}(x) = \frac{1}{\pi} \frac{\varepsilon}{x^2 + \varepsilon^2}$ form a family of approximations to the identity. On the other hand, it is also the case that
$$
\lim_{\varepsilon \to 0} - \varepsilon i m_{\mu}(t_0 + \varepsilon i) 
= \lim_{\varepsilon \to 0} - \varepsilon i \int \frac{1}{t - (t_0 + \varepsilon i)} \,d\mu(t)
= \lim_{\varepsilon \to 0} \mu(t_0) + o_{\varepsilon}(1)
= \mu(t_0),
$$  
which can be used to recover the atoms of $\mu$.

\subsection{Companion transform}
The {\bf companion} to the Stieltjes transform is defined for $z \in \mathbb{C} \setminus (\supp(\mu) \cup \{0\})$ as,
$$
v_{\mu}(z) := \gamma m_{\mu}(z) - \frac{1 - \gamma}{z}.
$$
This is simply the Stieltjes transform of $\underline{\mu} = \gamma \mu + (1 - \gamma) \delta_{0}$, and it describes the limiting spectrum of the matrix
$$
\frac{1}{p} \sum_{i = 1}^{p} \bx_{(j)} \bx_{(j)}^{\top}.
$$

\subsection{Inverse of the companion Stieltjes transform}
\label{sec:inverse-companion-transform}

Finally, the inverse of the companion Stieltjes transform $v^{-1}$ satisfies
$$
v_{\mu}^{-1}(v_{\mu}(z)) = z, \quad \textrm{for all}\quad z \in \mathbb{C}\setminus\supp(\mu).
$$
The inverse can be useful in computing the support of $\mu$. It can be shown that a point $x \in \Reals$ does not belong to the interior of the support of $\mu$, $x \not\in \mathrm{int}~\supp(\mu)$ if and only if $v_{\mu}(x) \in \Reals$; this is intuitively correct as $v_{\mu}(x) \in \Reals$ if and only if $f_{\mu}(x) = 0$. It follows that 
$$
\Reals \setminus \mathrm{int}~\supp(\mu) = v_{\mu}^{-1}\Big(\mathrm{range}(v_{\mu}(x)) \cap \Reals\Big).
$$
If further follows that if $x \in \mathrm{range}(v_{\mu}(x))$ then $v_{\mu}'(x) > 0$, therefore at $m = v_{\mu}(x)$ we have $(v_{\mu}^{-1})'(m) > 0$. In other words, 
$$
\mathrm{range}(v_{\mu}(x)) \cap \Reals \subseteq \{m \in \Reals: m \neq 0, (v_{\mu}^{-1})'(m) > 0 \} := \mc{D}_{\mu}.
$$
In fact, the two are exactly equal, and it follows that $v_{\mu}^{-1}(\mc{D}_{\mu}) = \Reals \setminus \mathrm{int}~\supp(\mu)$.




\section{Distribution of eigenvalues}
Let $\hat{H}_n(\tau)$ represent the empirical spectral distribution of the eigenvalues of $\bSigma$:
$$
\hat{H}_n(t) := \frac{1}{p} \sum_{i = 1}^{p} \1\{\lambda_i(\bSigma) \leq t\}.
$$
Suppose that $\hat{H}_n(t)$ converges weakly to a limiting spectral distribution $H(t)$ as $p \to \infty$. Then the spectral distribution $\hat{F}_n(t)$ of the sample covariance $\bS$ also converges to continuum limit $F_{\gamma,H}(t)$, which we will call a {\bf generalized Marchenko-Pastur distribution}. Random matrix theory provides the analytical tools necessary to prove this result and describe the resulting continuum limit. We give the result and sketch the proof.

\subsection{The fixed point equation}
Let $m_{\gamma,H}$ be the Stieltjes transform of the limiting generalized Marchenko-Pastur distribution $F_{\gamma,H}$. The companion transform is $v_{\gamma,H} := \gamma m_{\gamma,H}(z) - \frac{(1 - \gamma)}{z}$. It can be shown, via the leave-one-out approach, that the companion transform satisfies the self-consistency equation
\begin{equation}
	\label{eqn:silverstein}
	z = -\frac{1}{v(z)} + \gamma \int \frac{t}{1 + tv(z)} \,dH(t), \quad \textrm{for all $z \in \C_{+}$.}
\end{equation}
Equation~\eqref{eqn:silverstein} can be manipulated to show that the inverse of the companion transform satisfies
\begin{equation}
\label{eqn:inverse-fixed-point}
v_{\gamma,H}^{-1}(z) = -\frac{1}{z} + \gamma\int\frac{\tau}{1 + \tau z} \,dH(\tau). 
\end{equation} 
This will be useful in computing the support of $H$. 

\subsection{The companion transform}
To begin, let $\bB = \bS^{\top} = \frac{1}{n} \bX^{\top} \bX \in \Reals^{n \times n}$. We will assume without loss of generality that $\bSigma$ is diagonal with elements $\tau_1,\ldots,\tau_p$, and write $\bB = \bQ \bSigma \bQ$, where $\bQ_{ij} \sim N(0,1/n)$, all independent. 

The spectral distribution of $\bB$ is 
$$
\bar{F}_n(t) = \frac{1}{n}\sum_{i = 1}^{n} \1\{\lambda_i(\bB) \leq t\} = \gamma \hat{F}_n(t) + \max\{(1 - \gamma),0\} \1\{t \leq 0\},
$$
so the Stieltjes transform of $\bB$ is 
$$
v_n(z) = \frac{1}{n} \tr\Big((\bB - z\bI)^{-1}\Big) = \gamma m_n(z) - \frac{(1 - \gamma)}{z}.
$$
The transform $v_n$ is called the {\bf companion transform} of $m_n$. We will sketch an argument showing that the companion transform converges in the proportional asymptotic limit. To begin, we make the following simplifying approximations:
\begin{align*}
	\bq_{(j)}^{\top} (\bB - z\bI)^{-1} \bq_{(j)} & \approx \mathbb{E}[\bq_{(j)}^{\top} (\bB - z\bI)^{-1} \bq_{(j)}] \\
	\bq_{(j)}^{\top} (\bB_j - z\bI)^{-1} \bq_{(j)} & \approx \mathbb{E}[\bq_{(j)}^{\top} (\bB_j - z\bI)^{-1} \bq_{(j)}] \\
	v_n(z) := \frac{1}{n}\tr(\bB - z \bI)^{-1} & \approx \mathbb{E} v_n(z) \\
	\mathbb{E}{\frac{1}{n}\tr(\bB - z \bI)^{-1}} & \approx \mathbb{E}{\frac{1}{n}\tr(\bB_j - z \bI)^{-1}}.
\end{align*}


\subsection{The high-level argument}
Let $\bq_{(j)} \in \Reals^{n}$ be the $j$th column of $\bQ$ and notice that 
$$
\bB = \sum_{j = 1}^{p} \tau_j \bq_{(j)} \bq_{(j)}^{\top}.
$$
The key argument involves the concentration of terms of the form $\bq_{(j)}^{\top} (\bB - z\bI)^{-1} \bq_{(j)}$. Via the Sherman-Morrison formula, 
$$
(\bB - z\bI)^{-1} 
= (\bB_j -  z \bI + \tau_j \bq_{(j)} \bq_{(j)}^{\top})^{-1} 
= (\bB_j - z\bI)^{-1} - \frac{\tau_j (\bB_j - z\bI)^{-1} \bq_{(j)} \bq_{(j)}^{\top} (\bB_j - z\bI)^{-1}}{1 + \tau_j \bq_{(j)}^{\top}(\bB_j - z\bI)^{-1}\bq_{(j)}}
$$
hence,
\begin{align*}
\bq_{(j)}^{\top} (\bB - z\bI)^{-1} \bq_{(j)} 
& = \bq_{(j)}^{\top} (\bB_j - z\bI)^{-1} \bq_{(j)} - \frac{\tau_j}{1 + \tau_j \bq_{(j)}^{\top}(\bB_j - z\bI)^{-1}\bq_{(j)}} (\bq_{(j)}^{\top} (\bB_j - z\bI)^{-1} \bq_{(j)})^2 \\
& = \frac{\bq_{(j)}^{\top} (\bB_j - z\bI)^{-1} \bq_{(j)}}{1 + \tau_j \bq_{(j)}^{\top}(\bB_j - z\bI)^{-1}\bq_{(j)}}.
\end{align*}
Since $q_{(j)}$ and $B_j$ are independent,
$$
\mathbb{E}[\bq_{(j)}^{\top} (\bB_j - z\bI)^{-1} \bq_{(j)}|\bX_{(-j)}] =  \frac{1}{n}\tr(\bB_j - z\bI)^{-1}.
$$
Thus, using two of our simplifying approximations, we have that
$$
\bq_{(j)}^{\top} (\bB_j - z\bI)^{-1} \bq_{(j)}  \approx \mathbb{E}[\bq_{(j)}^{\top} (\bB_j - z\bI)^{-1} \bq_{(j)}] = \E[\frac{1}{n}\tr(\bB_j - z\bI)^{-1}]  \approx \mathbb{E}v_n(z),
$$
and therefore
$$
\bq_{(j)}^{\top} (\bB - z\bI)^{-1} \bq_{(j)} \approx \frac{\E v_n(z)}{1 + \tau_j \E v_n(z)}.
$$
Now, multiplying the left hand side by $\tau_j$ and averaging over $j$ gives
$$
\frac{1}{p}\sum_{j = 1}^{p} \tau_j \bq_{(j)}^{\top} (\bB - z\bI)^{-1} \bq_{(j)} = \frac{1}{p} \tr(\bB (\bB - z\bI)^{-1}) 
= \frac{1}{p} \tr(\bI_n + z (\bB - z\bI)^{-1} ) = \frac{1}{\gamma} + \frac{1}{\gamma} v_n(z)
\approx \frac{1}{\gamma} + \frac{1}{\gamma}\E v_n(z).
$$
Doing the same to the right hand side, we see that
\begin{equation}
\label{eqn:approximate-silverstein}
\frac{1}{\gamma} + \frac{1}{\gamma} \E v_n(z) \approx \frac{1}{\gamma} + \frac{1}{\gamma}\E v_n(z) \approx \frac{1}{p} \sum_{j = 1}^{p} \frac{\tau_j \E v_n(z)}{1 + \tau_j \E v_n(z)} \to \int \frac{\tau \E v_n(z)}{1 + \tau \E v_n(z)} \,dH(\tau).
\end{equation}
Rearranging~\eqref{eqn:approximate-silverstein} gives back~\eqref{eqn:silverstein}.

\section{Distribution of eigenvectors}
Define the following population and sample spectral distributions of a vector $\bbeta \in \Reals^p$:
$$
\wh{G}_n(\tau) := \frac{1}{\|\bbeta\|^2} \sum_{j = 1}^{p} (\bbeta_j^{\top} \bw_j)^2 \1\{\lambda_i(\bSigma) \leq \tau\}, \quad \wh{B}_n(\tau) := \frac{1}{\|\bbeta\|^2} \sum_{j = 1}^{p} (\bbeta_j^{\top} \bv_j)^2 \1\{\lambda_i(\bS) \leq \tau\}
$$ 
Obviously, taking $\bbeta = \bw$ means that $\wh{B}_n$ describes the correlation between the leading eigenspaces $\mathrm{span}\{\bv_1,\ldots,\bv_j\}$ and a true eigenvector of $\bSigma$. (Although, notice that the limit of $\wh{B}_n$ does not contain enough microscopic information to describe the asymptotic correlation between a population eigenvector and an individual sample eigenvector.)

The limit of $\wh{B}_n$, as $n,p \to \infty, p/n \to \gamma \in (0,\infty)$ and $\hat{G}_n \convweak G$, can be computed by finding the limit of the Stieltjes transform of $\hat{B}_n$ and applying the Stieltjes inversion formula. The fundamental ideas used to derive the limit of the Stieltjes transform of $m_{\wh{B}_n}$ are largely the same as for eigenvalues, but the calculations are a bit more tedious. 

\subsection{The high-level argument}
Introduce the resolvent notation 
$$
\bB = \frac{1}{n} \bSigma^{1/2} \bZ \bZ^{\top} \bSigma^{1/2}, \quad \bQ = (\bB - z\bI)^{-1}, \quad \bP = \bP(\hat{e}) = (x(\hat{e})\bSigma - z\bI)^{-1},
$$
where $\hat{e} = \frac{1}{p}\tr(\bSigma \bQ)$, and $x(\hat{e}) = \frac{1}{1 + \gamma \hat{e}}$. (Notice that the notation has shifted from last section.) The idea is to show that for a relatively general class of matrices $\bTheta$,
\begin{equation}
	\label{eqn:matrix-resolvent-convergence}
	\frac{1}{n}\tr(\bTheta \bQ- \bTheta \bP) \to 0.
\end{equation}
This is accomplished by leave-one-out arguments. By the resolvent identity,
$$
\bP - \bQ = \bP (\bQ^{-1} - \bP^{-1}) \bQ = \bP (\bB - x(\hat{e})\bSigma) \bQ. 
$$
Writing $\bB = \frac{1}{n}\sum_{i = 1}^{n} \bSigma^{1/2} \bz_i \bz_i^{\top} \bSigma^{1/2}$, we have from Sherman-Morrison that
\begin{align*}
\bB \bQ 
& = \frac{1}{n}\sum_{i = 1}^{n} \bSigma^{1/2} \bz_i \bz_i^{\top}  \bSigma^{1/2}  \bQ \\
& = \frac{1}{n}\sum_{i = 1}^{n} \bSigma^{1/2} \bz_i \bz_i^{\top}  \bSigma^{1/2}  \Big(\bQ_i - \frac{\bQ_i \bSigma^{1/2} \bz_i \bz_i^{\top}  \bSigma^{1/2} \bQ_i}{1 + \bz_i^{\top} \bSigma^{1/2} \bQ_i \bSigma^{1/2} \bz_i}\Big) \\
& = \frac{1}{n}\sum_{i = 1}^{n} \bSigma^{1/2} \bz_i  \Big(1 - \frac{\bz_i^{\top}  \bSigma^{1/2} \bQ_i \bSigma^{1/2} \bz_i }{1 + \bz_i^{\top} \bSigma^{1/2} \bQ_i \bSigma^{1/2} \bz_i}\Big) \bz_i^{\top}  \bSigma^{1/2} \bQ_i \\
& = \frac{1}{n}\sum_{i = 1}^{n} \frac{\bSigma^{1/2} \bz_i \bz_i^{\top}  \bSigma^{1/2} \bQ_i}{{1 + \bz_i^{\top} \bSigma^{1/2} \bQ_i \bSigma^{1/2} \bz_i}}.
\end{align*}
Now, assuming as before that differences between empirical means and expectations are negligible, so that we can move between them as needed, we have that
\begin{align*}
\tr(\wt{\bTheta} \bSigma^{1/2} \bz_i \bz_i^{\top}  \bSigma^{1/2} \bQ_i) & \approx \frac{1}{n}\tr(\wt{\bTheta} \bSigma \bQ) \\
\bz_i^{\top} \bSigma^{1/2} \bQ_i \bSigma^{1/2} \bz_i & \approx \frac{1}{n}\tr(\bSigma \bQ) = \gamma \hat{e}.
\end{align*}
Thus 
$$
\tr(\wt{\bTheta} \bB \bQ) \approx \frac{\tr(\wt{\bTheta} \bSigma \bQ)}{1 + \gamma \hat{e}} =  x(\hat{e}) \tr(\wt{\bTheta} \bSigma \bQ),
$$
establishing~\eqref{eqn:matrix-resolvent-convergence} upon taking $\wt{\bTheta} = \bTheta \bP$. 

One more empirical object $\hat{e}$ remains, but the preceding arguments show what its limit should be. In particular, taking $\bTheta = \bSigma$, we conclude that
$$
f_n(\hat{e}) := \frac{\hat{e}}{\gamma} - \frac{1}{n}\tr\big(\bSigma \bP(\hat{e})\big) \to 0.
$$
Letting $e_n^{\ast}$ be such that $f_n(e_n^{\ast}) = 0$, it can be shown that $f_n(\hat{e}) \to 0$ implies $\hat{e} \to e_n^{\ast}$, and thus
\begin{equation}
	\frac{1}{n}\tr(\bTheta \bQ) - \frac{1}{n}\tr(\bTheta \bP(e_n^{\ast})) \to 0.
\end{equation}
Taking the limit of $\frac{1}{n}\tr(\bTheta \bP(e_n^{\ast}))$, we arrive at the following:
$$
m_{\hat{B}_n}(z) \to \int \frac{1}{\tau x(e^{\ast}) - z} \,dG(\tau), \quad \textrm{where} \quad e^{\ast} = \int \frac{\tau}{\tau x(e^{\ast}) - z} \,dH(\tau).
$$
Finally, manipulating the above self-consistency equation for $e^{\ast}$ gives that $x^{\ast} = x(e^{\ast}) = -z v(z)$, since
\begin{align*}
	\frac{1}{x^{\ast}} - 1 = \gamma \int \frac{\tau}{\tau x^{\ast} - z} \,dH(\tau) \Longleftrightarrow z = \frac{z}{x^{\ast}} - \gamma \int \frac{\tau}{\frac{-\tau x^{\ast}}{z} + 1} \,dH(\tau),
\end{align*}
showing that $-x^{\ast}/z$ solves the self-consistency equation~\eqref{eqn:silverstein}. Thus, 
$$
m_{\hat{B}_n}(z) \to \int \frac{1}{-z \tau v(z) - z} \,dG(\tau) = -\frac{1}{z} \int \frac{1}{\tau v(z) + 1} \,dG(\tau) = m_{B}(z).
$$
\subsection{The inversion formula}
Finally, applying the inversion formula, the density of $f_{B}(\theta)$ at any $\theta \in \supp(B)$ is given by
$$
f_{B}(\theta) = \frac{1}{\pi}\lim_{\varepsilon \to} \Im(m_B(\theta + \varepsilon i)) = \frac{1}{\theta} \int \frac{\tau \gamma f_{\gamma,H}(\theta)}{|1 + \tau v(\theta)|^2} \,dG(\tau),
$$
assuming this limit is finite. If the limit is infinite, then $\theta$ is a potential atom of $B$. 

\section{Examples}

\subsection{Identity covariance}

The most basic case is $\bSigma = \bI, \gamma < 1$, $\hat{H}_n(\tau) = H_1(\tau) = \1\{\tau \leq 1\}$. In this case $\hat{F}_n(t)$ converges weakly to the {\bf Marchenko-Pastur distribution} $F_{\gamma}(t)$. The Marchenko-Pastur distribution has a density $f_{\gamma}(t)$ supported on $[t^{-},t^{+}] := [1 - \sqrt{\gamma}, 1 + \sqrt{\gamma}]$, with 
$$
f_{\gamma}(t) := \frac{\sqrt{(t^{+} - t)(t - t^{-})}}{2 \pi \gamma t}, \quad \textrm{for $t \in [t^{-},t^{+}]$.}
$$
If additionally $\gamma > 1$, then $F_{\gamma}$ has an atom at $0$ of magnitude $1 - 1/\gamma$. 

To show this, notice that when $H = \delta_1$ the self-consistency equation~\eqref{eqn:silverstein} reduces to
$$
z = -\frac{1}{v(z)} + \frac{\gamma}{1 + v(z)}.
$$
Using the definition of $m = \gamma v - (1 - \gamma)/z$, this can be rearranged to 
$$
m(z)= \frac{1}{(1 - \gamma) - \gamma m z - z}.
$$
Taking the resulting quadratic equation and solving for $m$ yields two solutions, 
$$
\frac{(1 - \gamma - z) \pm \sqrt{(1 + \gamma - z)^2 - 4 \gamma}}{2 \gamma z}.
$$
If we adopt the usual convention that $\sqrt{z} \in \mathbb{C}_{+}$ refers to the positive branch of a complex number, then recalling that $m(z) \in \mathbb{C}_{+}$, it follows that 
\begin{align*}
m_{\gamma}(z) 
& = \frac{(1 - \gamma - z) + \sqrt{(1 + \gamma - z)^2 - 4 \gamma}}{2 \gamma z} \\
& = \frac{(1 - \gamma - z) + \sqrt{( (1 + \sqrt{\gamma})^2 - z)((1 - \sqrt{\gamma})^2 - z)}}{2 \gamma z}.
\end{align*}
From here we can compute the density of the Marchenko-Pastur distribution by applying the Stieltjes inversion formula:
\begin{align*}
f_{\gamma}(t) 
& = \frac{1}{\pi}\lim_{\varepsilon \to 0} \Im m_{\gamma}(t + i \varepsilon) \\
& = \frac{1}{\pi} \Im \frac{\sqrt{( (1 + \sqrt{\gamma})^2 - t)((1 - \sqrt{\gamma})^2 - t)}}{2 \gamma t} \\
& = \frac{1}{\pi} \frac{\sqrt{( (1 + \sqrt{\gamma})^2 - t)(t - (1 - \sqrt{\gamma})^2)}}{2 \gamma t}.
\end{align*}
Meanwhile,
$$
m_{B_{\gamma}}(\theta) = -\frac{1}{\theta(v_{\gamma}(\theta) + 1)} \textcolor{red}{= m_{\gamma}(\theta)}, 
$$
showing that $B_{\gamma} = F_{\gamma}$, as one would expect.

\subsection{Spiked covariance, one-spike}
The next case that will be considered is the one-spiked covariance model where $\bSigma = (\ell - 1) \bbeta \bbeta^{\top} + \bI$ for some $\ell \geq 1$, where $\|\bbeta\|^2 = 1$ and $\bbeta, \ell$ are fixed in $n$. As in the identity covariance model $\hat{H}_n(\tau) \to H_1(\tau)$, and so $\hat{F}_n(t) \to F_{\gamma}(t)$. 

Unlike in the identity covariance case, $G_n \to \delta_{\ell}$. Therefore the Stieltjes transform of the empirical spectral distribution of $\beta$ has limit
\begin{equation}
\label{eqn:spiked-covarinace-limiting-stieltjes}
m_{B_{\ell}}(\theta) = -\frac{1}{\theta} \cdot \frac{1}{\ell v(\theta) + 1}. 
\end{equation}
Clearly $m_B(\theta) \in \Reals$ if and only if $v(\theta) \in \Reals$ and $v(\theta) \neq -(1/\ell)$. Since singletons do not contribute to the $\interior(\supp(B))$, it follows that 
$$
\interior(\supp(B)) = \interior(\supp(F_\gamma)) = (1 - \sqrt{\gamma}, 1 + \sqrt{\gamma}).
$$
For $\theta \in (1 - \sqrt{\gamma}, 1 + \sqrt{\gamma})$, the density of $B_{\ell}$ is given by the Stieljes inversion formula. We work through the tedious algebraic details for completeness. First of all, the companion transform can be written as 
\begin{align*}
v_{\gamma}(\theta) 
& = \gamma m_{\gamma}(\theta) - \frac{1 - \gamma}{\theta} \\
& = \gamma \bigg\{\frac{(1 - \gamma - \theta) + \sqrt{(1 + \gamma - \theta)^2 - 4 \gamma}}{2 \gamma \theta}\bigg\}- \frac{(1 - \gamma)}{\theta} \\
& = -\frac{1}{2} - \frac{(1 - \gamma)}{2 \theta} + \frac{\sqrt{(1 + \gamma - \theta)^2 - 4 \gamma}}{2\theta}.
\end{align*}
A calculation then gives
\begin{align*}
|1 + \ell v(\theta)|^2 
& = 
\bigg|1 - \frac{\ell}{2} - \frac{(1 - \gamma)\ell}{2 \theta} + \frac{\ell\sqrt{(1 + \gamma - \theta)^2 - 4 \gamma}}{2\theta}\bigg|^2 \\
& = 
\bigg(1 - \frac{(1 - \gamma + \theta)\ell}{2 \theta}\bigg)^2 - \frac{\ell^2\Big((1 + \gamma - \theta)^2 - 4 \gamma\Big)}{4\theta^2} \\
& = 
1 - \frac{(1 - \gamma + \theta)\ell}{ \theta} + \frac{\ell^2(1 - \gamma + \theta)^2- (1 + \gamma - \theta)^2}{4\theta^2} + \frac{\ell^2\gamma}{\theta^2} \\
& = 1 - \frac{(1 - \gamma + \theta)\ell}{ \theta} + \frac{\ell^2}{\theta}. 
\end{align*}
Therefore, 
\begin{align*}
f_{B_{\ell}}(\theta) & = \frac{1}{\theta} \frac{\ell \gamma f_{\gamma}(\theta)}{|1 + \ell v(\theta)|^2}  = \frac{\gamma \ell}{\theta + \ell(\gamma - 1 - \theta) + \ell^2} f_{\gamma}(\theta), \quad \textrm{for $\theta \in (1 - \sqrt{\gamma}, 1 + \sqrt{\gamma}).$}
\end{align*}
It can be shown that this holds at the boundaries $\theta = \pm(1 - \sqrt{\gamma})$ as well.

Finally, it can be seen from~\eqref{eqn:spiked-covarinace-limiting-stieltjes} that there is a potential atom in $B_{\ell}$ if there exists $\theta \in \Reals_{+}$ such that $v_{\gamma}(\theta) = -1/\ell$, in other words, if $-1/\ell \in \range(v_{\gamma})$. As detailed in Section~\ref{sec:inverse-companion-transform}, the range of $v_{\gamma}$ can be identified from the inverse of the Stieltjes transform. The inverse of the Stieltjes transform is given in~\eqref{eqn:inverse-fixed-point}, and in the special case where $H = \delta_1$:
$$
v_{\gamma}^{-1}(z) = -\frac{1}{z} + \frac{\gamma}{1 + z}.
$$
It follows that
$$
(v_{\gamma}^{-1})'(z) = \frac{1}{z^2} - \frac{\gamma}{(1 + z)^2},
$$
which is strictly positive when $-1/z > (1 + \sqrt{\gamma})$. In other words, $-1/\ell \in \range(v_{\gamma})$ if $\ell > (1 + \sqrt{\gamma})$. Thus, if $\ell > (1 + \sqrt{\gamma})$, there exists an atom at 
$$
v_{\gamma}^{-1}(-1/\ell) = \ell + \frac{\gamma \ell}{\ell - 1} =: \theta_l,
$$
and the weight of the atom is given by
\begin{align*}
\lim_{\varepsilon \to 0} - \varepsilon i m_{B}(\theta + \varepsilon i) 
& = \frac{-1}{\ell \theta_\ell v_{\gamma}'(\theta_l)} = \frac{(v_{\gamma}^{-1})'(-1/\ell)}{\ell \theta_{\ell}} \\
& = \frac{\ell - 1 - \sqrt{\gamma}}{\ell - 1}.
\end{align*}


	
	
\end{document}